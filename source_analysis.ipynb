{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by Sitong Chen\n",
    "This code is for source analysis of EEG data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "import mne\n",
    "from mne.io.constants import FIFF\n",
    "import mne\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from mne.coreg import Coregistration\n",
    "from mne.viz import Brain\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse_epochs,apply_inverse\n",
    "from mne import setup_source_space, setup_volume_source_space\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.channels import make_dig_montage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_task\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m brainvision_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     14\u001b[0m     bids_root, \n\u001b[0;32m     15\u001b[0m     subject_name, \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mses-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ses-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_task-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_run-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_eeg.vhdr\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_custom_montage\u001b[39m(coord_file):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a custom montage from the coordinates file.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the path to the Brain Vision files in the BIDS dataset\n",
    "onset_start = -0.2\n",
    "onset_end = 0.8\n",
    "time_start = 0\n",
    "time_end = 10\n",
    "# Define the path to the Brain Vision files in the BIDS dataset\n",
    "bids_root = 'example_root'\n",
    "subject_name = \"example_name\"\n",
    "session = \"example_session\"\n",
    "run = \"example_run\"\n",
    "task = \"example_task\"\n",
    "output_dir = f'example_path'\n",
    "\n",
    "fsaverage_data_dir = 'example_fsaverage_path'  \n",
    "mne.datasets.sample.data_path(verbose=True)\n",
    "sample_data_dir = mne.datasets.sample.data_path()\n",
    "subject_dir = os.path.join(sample_data_dir, 'subjects')\n",
    "subject = 'fsaverage'\n",
    "\n",
    "\n",
    "brainvision_path = os.path.join(\n",
    "    bids_root, \n",
    "    subject_name, \n",
    "    f'ses-{session}', \n",
    "    'eeg', \n",
    "    f'{subject_name}_ses-{session}_task-{task}_run-{run}_eeg.vhdr'\n",
    ")\n",
    "\n",
    "def create_custom_montage(coord_file):\n",
    "    \"\"\"Create a custom montage from the coordinates file.\"\"\"\n",
    "    coords = pd.read_csv(coord_file, sep='\\t')\n",
    "\n",
    "    # Prepare lists for names and positions\n",
    "    names = coords['name'].tolist()\n",
    "    positions = np.array([coords['x'], coords['y'], coords['z']]).T\n",
    "\n",
    "    # Create the montage\n",
    "    montage = make_dig_montage(ch_pos={name: pos for name, pos in zip(names, positions)},\n",
    "                               nasion=None,\n",
    "                               lpa=None,\n",
    "                               rpa=None)\n",
    "\n",
    "    return montage\n",
    "\n",
    "# Read the Brain Vision data into a Raw object\n",
    "raw = mne.io.read_raw_brainvision(brainvision_path, preload=True)\n",
    "\n",
    "coord_file = f'{bids_root}/{subject_name}/ses-{session}/eeg/{subject_name}_ses-{session}_space-CapTrak_electrodes.tsv'\n",
    "\n",
    "# Create the custom montage using the coordinates\n",
    "montage = create_custom_montage(coord_file)\n",
    "\n",
    "# Set the custom montage\n",
    "raw.set_montage(montage)\n",
    "raw.get_montage\n",
    "# Preprocess: Set EEG reference and apply projection\n",
    "raw.set_eeg_reference('average', projection=True)\n",
    "raw.apply_proj()\n",
    "\n",
    "# **Extract events from annotations**\n",
    "events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "raw.crop(tmin=time_start, tmax=time_end)\n",
    "\n",
    "epochs = mne.Epochs(\n",
    "    raw, \n",
    "    events, \n",
    "    event_id= None, \n",
    "    tmin=onset_start, \n",
    "    tmax=onset_end, \n",
    "    # baseline=(None, 0), \n",
    "    baseline=None,\n",
    "    preload=True\n",
    ")\n",
    "info = epochs.info\n",
    "epochs.plot_drop_log()\n",
    "# 确保输出目录存在，如果不存在则创建\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 定义文件路径\n",
    "info_fname = os.path.join(output_dir, 'info.pkl')\n",
    "\n",
    "# 如果文件不存在则创建\n",
    "if not os.path.exists(info_fname):\n",
    "    with open(info_fname, 'wb') as f:\n",
    "        pickle.dump(info, f)\n",
    "    print(f\"Info object saved to {info_fname}\")\n",
    "else:\n",
    "    print(f\"Info file already exists: {info_fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DigMontage | 0 extras (headshape), 0 HPIs, 3 fiducials, 128 channels>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montage = raw.get_montage()\n",
    "montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.drop_log \n",
    "evoked = epochs.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading surfaces...\n",
      "\n",
      "Loading the solution matrix...\n",
      "\n",
      "Three-layer model surfaces loaded.\n",
      "Loaded linear collocation BEM solution from d:\\000data\\Chinese_reading_task_eeg_processing-main\\Chinese_reading_task_eeg_processing-main\\data_preprocessing_and_alignment\\..\\data\\mne_src\\mne_data\\MNE-fsaverage-data\\fsaverage\\bem\\fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Setting up the source space with the following parameters:\n",
      "\n",
      "SUBJECTS_DIR = C:\\Users\\17893\\mne_data\\MNE-sample-data\\subjects\n",
      "Subject      = fsaverage\n",
      "Surface      = white\n",
      "Octahedron subdivision grade 6\n",
      "\n",
      ">>> 1. Creating the source space...\n",
      "\n",
      "Doing the octahedral vertex picking...\n",
      "Loading C:\\Users\\17893\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\surf\\lh.white...\n",
      "Mapping lh fsaverage -> oct (6) ...\n",
      "    Warning: zero size triangles: [3 4]\n",
      "    Triangle neighbors and vertex normals...\n",
      "Loading geometry from C:\\Users\\17893\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\surf\\lh.sphere...\n",
      "Setting up the triangulation for the decimated surface...\n",
      "loaded lh.white 4098/163842 selected to source space (oct = 6)\n",
      "\n",
      "Loading C:\\Users\\17893\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\surf\\rh.white...\n",
      "Mapping rh fsaverage -> oct (6) ...\n",
      "    Warning: zero size triangles: [3 4]\n",
      "    Triangle neighbors and vertex normals...\n",
      "Loading geometry from C:\\Users\\17893\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\surf\\rh.sphere...\n",
      "Setting up the triangulation for the decimated surface...\n",
      "loaded rh.white 4098/163842 selected to source space (oct = 6)\n",
      "\n",
      "Calculating source space distances (limit=inf mm)...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "You are now one step closer to computing the gain matrix\n",
      "Overwriting existing file.\n",
      "BEM solution saved to ../data/mne_src/mne_src/sub-m2/source_data\\bem-sol.fif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bem_fname = os.path.join(subject_dir, subject, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "\n",
    "if not os.path.exists(bem_fname):\n",
    "    raise FileNotFoundError(f\"BEM solution not found at {bem_fname}\")\n",
    "bem = mne.read_bem_solution(bem_fname)\n",
    "src = mne.setup_source_space(subject, subjects_dir=subject_dir, add_dist=True)\n",
    "# Save the BEM solution\n",
    "bem_fname_saved = os.path.join(output_dir, 'bem')\n",
    "mne.write_bem_solution(os.path.join(output_dir, 'bem-sol.fif'), bem,overwrite=True)\n",
    "print(f\"BEM solution saved to {os.path.join(output_dir, 'bem-sol.fif')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/mne_src/mne_src/sub-m2/source_data\n"
     ]
    }
   ],
   "source": [
    "# Save the source space as a pickle file\n",
    "src_file = os.path.join(output_dir, 'src.pkl')\n",
    "with open(src_file, 'wb') as f:\n",
    "    pickle.dump(src, f)\n",
    "\n",
    "# Optionally, save the settings for the plot (e.g., view parameters)\n",
    "alignment_settings = {\n",
    "    'azimuth': 180,\n",
    "    'elevation': 90,\n",
    "    'distance': 0.30,\n",
    "    'focalpoint': (-0.03, -0.01, 0.03)\n",
    "}\n",
    "\n",
    "# Save the alignment settings as a pickle file\n",
    "settings_file = os.path.join(output_dir, 'alignment_settings.pkl')\n",
    "with open(settings_file, 'wb') as f:\n",
    "    pickle.dump(alignment_settings, f)\n",
    "\n",
    "print(f\"Data saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.datasets import fetch_fsaverage\n",
    "fetch_fsaverage(verbose=True)\n",
    "\n",
    "fiducials = 'estimated'\n",
    "subject = 'fsaverage'\n",
    "coreg = Coregistration(info, subject,subjects_dir=subject_dir,fiducials=fiducials)\n",
    "coreg.fit_fiducials(verbose=True)\n",
    "coreg.fit_icp(n_iterations=6, nasion_weight=2.0, verbose=True)\n",
    "coreg.omit_head_shape_points(distance=5.0 / 1000)  # distance is in meters\n",
    "coreg.fit_icp(n_iterations=20, nasion_weight=10.0, verbose=True)\n",
    "dists = coreg.compute_dig_mri_distances() * 1e3  # in mm\n",
    "print(\n",
    "    f\"Distance between HSP and MRI (mean/min/max):\\n{np.mean(dists):.2f} mm \"\n",
    "    f\"/ {np.min(dists):.2f} mm / {np.max(dists):.2f} mm\"\n",
    ")\n",
    "trans = coreg.trans\n",
    "trans_fname = os.path.join(output_dir, 'trans.fif')\n",
    "mne.write_trans(trans_fname, coreg.trans,overwrite=True)\n",
    "print(f\"Transformation matrix saved to {trans_fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading forward solution from d:\\000data\\Chinese_reading_task_eeg_processing-main\\Chinese_reading_task_eeg_processing-main\\data_preprocessing_and_alignment\\..\\data\\mne_src\\mne_src_11\\source_data\\fwd-fwd.fif...\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523 (FIFF_MNE_FORWARD_SOLUTION_GRAD)) not available\n",
      "    Read EEG forward solution (8196 sources, 128 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n"
     ]
    }
   ],
   "source": [
    "fwd = mne.make_forward_solution(\n",
    "info = info,\n",
    "trans = trans,\n",
    "src = src,\n",
    "bem = bem,\n",
    "meg = False,\n",
    "eeg=True,\n",
    "mindist=0.0,\n",
    "n_jobs=8,\n",
    "verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadfield = fwd[\"sol\"][\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Created an SSP operator (subspace dimension = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17893\\AppData\\Local\\Temp\\ipykernel_38736\\3239185189.py:1: RuntimeWarning: Epochs are not baseline corrected, covariance matrix may be inaccurate\n",
      "  noise_cov = mne.compute_covariance(epochs, tmin=start, tmax=end, method=[\"shrunk\", \"empirical\"], rank=None, verbose=True, n_jobs=8)\n",
      "C:\\Users\\17893\\AppData\\Local\\Temp\\ipykernel_38736\\3239185189.py:1: RuntimeWarning: epochs._get_data() can't run because this Epochs-object is empty. You might want to check Epochs.drop_log or Epochs.plot_drop_log() to see why epochs were dropped.\n",
      "  noise_cov = mne.compute_covariance(epochs, tmin=start, tmax=end, method=[\"shrunk\", \"empirical\"], rank=None, verbose=True, n_jobs=8)\n",
      "C:\\Users\\17893\\AppData\\Local\\Temp\\ipykernel_38736\\3239185189.py:1: RuntimeWarning: epochs._get_data() can't run because this Epochs-object is empty. You might want to check Epochs.drop_log or Epochs.plot_drop_log() to see why epochs were dropped.\n",
      "  noise_cov = mne.compute_covariance(epochs, tmin=start, tmax=end, method=[\"shrunk\", \"empirical\"], rank=None, verbose=True, n_jobs=8)\n",
      "C:\\Users\\17893\\AppData\\Local\\Temp\\ipykernel_38736\\3239185189.py:1: RuntimeWarning: epochs._get_data() can't run because this Epochs-object is empty. You might want to check Epochs.drop_log or Epochs.plot_drop_log() to see why epochs were dropped.\n",
      "  noise_cov = mne.compute_covariance(epochs, tmin=start, tmax=end, method=[\"shrunk\", \"empirical\"], rank=None, verbose=True, n_jobs=8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 128 -> 127\n",
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "Number of samples used : 3216\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -313.264\n",
      "   empirical: -497.199\n",
      "selecting best estimator: shrunk\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "noise_cov = mne.compute_covariance(epochs, tmin=start, tmax=end, method=[\"shrunk\", \"empirical\"], rank=None, verbose=True, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading inverse operator decomposition from d:\\000data\\Chinese_reading_task_eeg_processing-main\\Chinese_reading_task_eeg_processing-main\\data_preprocessing_and_alignment\\..\\data\\mne_src\\mne_src_11\\sub-01\\source_data\\inverse_operator...\n",
      "    Reading inverse operator info...\n",
      "    [done]\n",
      "    Reading inverse operator decomposition...\n",
      "    [done]\n",
      "    128 x 128 full covariance (kind = 1) found.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 128) active\n",
      "    Noise covariance matrix read.\n",
      "    24588 x 24588 diagonal covariance (kind = 2) found.\n",
      "    Source covariance matrix read.\n",
      "    24588 x 24588 diagonal covariance (kind = 6) found.\n",
      "    Orientation priors read.\n",
      "    24588 x 24588 diagonal covariance (kind = 5) found.\n",
      "    Depth priors read.\n",
      "    Did not find the desired covariance matrix (kind = 3)\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17893\\AppData\\Local\\Temp\\ipykernel_38736\\710362270.py:13: RuntimeWarning: This filename (../data/mne_src/mne_src_11/sub-01/source_data/inverse_operator) does not conform to MNE naming conventions. All inverse operator files should end with -inv.fif, -inv.fif.gz, _inv.fif or _inv.fif.gz\n",
      "  inverse_operator = read_inverse_operator(fname_inverse_operator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 128) active\n",
      "    Source spaces transformed to the inverse solution coordinate frame\n"
     ]
    }
   ],
   "source": [
    "from mne.minimum_norm import read_inverse_operator, apply_inverse_raw, apply_inverse\n",
    "inv_method = \"eLORETA\"  # sLORETA, MNE, dSPM\n",
    "\n",
    "lambda2 = 1 / 6\n",
    "\n",
    "inverse_operator = make_inverse_operator(\n",
    "    info, fwd, noise_cov, depth=0.8,\n",
    ")\n",
    "inverse_operator_fname = os.path.join(output_dir, 'inverse_operator')\n",
    "mne.minimum_norm.write_inverse_operator(inverse_operator_fname, inverse_operator,overwrite=True)\n",
    "print(f\"Inverse operator saved to {inverse_operator_fname}-inv.fif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 16\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Created the whitener using a noise covariance matrix with rank 127 (1 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 8 (8.9e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Applying inverse operator to \"0.00 × 1 + 0.00 × 2 + 0.00 × 3 + 0.50 × 4 + 0.50 × 5\"...\n",
      "    Picked 128 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "    Computing residual...\n",
      "    Explained  34.6% variance\n",
      "    Combining the current components...\n",
      "[done]\n",
      "Writing STC to disk...\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "[done]\n",
      "Source estimate saved to ../data/mne_src/mne_src/sub-m2/source_data\\source_estimate-stc.fif\n"
     ]
    }
   ],
   "source": [
    "stc = apply_inverse(evoked, inverse_operator, lambda2, method=inv_method, pick_ori=None)\n",
    "# stc = stc.copy().align_src(src)\n",
    "# Save the source estimate (stc)\n",
    "stc_fname = os.path.join(output_dir, 'source_estimate')\n",
    "stc.save(stc_fname,overwrite=True)\n",
    "print(f\"Source estimate saved to {stc_fname}-stc.fif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcs[0].plot(subjects_dir = subject_dir,subject = subject,surface = 'white',hemi = 'both', time_unit='s',time_viewer=True,src = src)\n",
    "\n",
    "stc.plot(subjects_dir = subject_dir,subject = subject,surface = 'white',hemi = 'both', time_unit='s',time_viewer=True,src = src)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogtasks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
