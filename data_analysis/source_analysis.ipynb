{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by Sitong Chen\n",
    "This code is for source analysis of EEG data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "import mne\n",
    "from mne.io.constants import FIFF\n",
    "import mne\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from mne.coreg import Coregistration\n",
    "from mne.viz import Brain\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse_epochs,apply_inverse\n",
    "from mne import setup_source_space, setup_volume_source_space\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.channels import make_dig_montage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the Brain Vision files in the BIDS dataset\n",
    "onset_start = -0.2\n",
    "onset_end = 0.8\n",
    "time_start = 0\n",
    "time_end = 10\n",
    "# Define the path to the Brain Vision files in the BIDS dataset\n",
    "bids_root = 'example_root'\n",
    "subject_name = \"example_name\"\n",
    "session = \"example_session\"\n",
    "run = \"example_run\"\n",
    "task = \"example_task\"\n",
    "output_dir = f'example_path'\n",
    "\n",
    "fsaverage_data_dir = 'example_fsaverage_path'  \n",
    "mne.datasets.sample.data_path(verbose=True)\n",
    "sample_data_dir = mne.datasets.sample.data_path()\n",
    "subject_dir = os.path.join(sample_data_dir, 'subjects')\n",
    "subject = 'fsaverage'\n",
    "\n",
    "\n",
    "brainvision_path = os.path.join(\n",
    "    bids_root, \n",
    "    subject_name, \n",
    "    f'ses-{session}', \n",
    "    'eeg', \n",
    "    f'{subject_name}_ses-{session}_task-{task}_run-{run}_eeg.vhdr'\n",
    ")\n",
    "\n",
    "def create_custom_montage(coord_file):\n",
    "    \"\"\"Create a custom montage from the coordinates file.\"\"\"\n",
    "    coords = pd.read_csv(coord_file, sep='\\t')\n",
    "\n",
    "    # Prepare lists for names and positions\n",
    "    names = coords['name'].tolist()\n",
    "    positions = np.array([coords['x'], coords['y'], coords['z']]).T\n",
    "\n",
    "    # Create the montage\n",
    "    montage = make_dig_montage(ch_pos={name: pos for name, pos in zip(names, positions)},\n",
    "                               nasion=None,\n",
    "                               lpa=None,\n",
    "                               rpa=None)\n",
    "\n",
    "    return montage\n",
    "\n",
    "# Read the Brain Vision data into a Raw object\n",
    "raw = mne.io.read_raw_brainvision(brainvision_path, preload=True)\n",
    "\n",
    "coord_file = f'{bids_root}/{subject_name}/ses-{session}/eeg/{subject_name}_ses-{session}_space-CapTrak_electrodes.tsv'\n",
    "\n",
    "# Create the custom montage using the coordinates\n",
    "montage = create_custom_montage(coord_file)\n",
    "\n",
    "# Set the custom montage\n",
    "raw.set_montage(montage)\n",
    "raw.get_montage\n",
    "# Preprocess: Set EEG reference and apply projection\n",
    "raw.set_eeg_reference('average', projection=True)\n",
    "raw.apply_proj()\n",
    "\n",
    "# **Extract events from annotations**\n",
    "events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "raw.crop(tmin=time_start, tmax=time_end)\n",
    "\n",
    "epochs = mne.Epochs(\n",
    "    raw, \n",
    "    events, \n",
    "    event_id= None, \n",
    "    tmin=onset_start, \n",
    "    tmax=onset_end, \n",
    "    # baseline=(None, 0), \n",
    "    baseline=None,\n",
    "    preload=True\n",
    ")\n",
    "info = epochs.info\n",
    "epochs.plot_drop_log()\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "info_fname = os.path.join(output_dir, 'info.pkl')\n",
    "\n",
    "if not os.path.exists(info_fname):\n",
    "    with open(info_fname, 'wb') as f:\n",
    "        pickle.dump(info, f)\n",
    "    print(f\"Info object saved to {info_fname}\")\n",
    "else:\n",
    "    print(f\"Info file already exists: {info_fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = raw.get_montage()\n",
    "montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.drop_log \n",
    "evoked = epochs.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bem_fname = os.path.join(subject_dir, subject, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "\n",
    "if not os.path.exists(bem_fname):\n",
    "    raise FileNotFoundError(f\"BEM solution not found at {bem_fname}\")\n",
    "bem = mne.read_bem_solution(bem_fname)\n",
    "src = mne.setup_source_space(subject, subjects_dir=subject_dir, add_dist=True)\n",
    "# Save the BEM solution\n",
    "bem_fname_saved = os.path.join(output_dir, 'bem')\n",
    "mne.write_bem_solution(os.path.join(output_dir, 'bem-sol.fif'), bem,overwrite=True)\n",
    "print(f\"BEM solution saved to {os.path.join(output_dir, 'bem-sol.fif')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the source space as a pickle file\n",
    "src_file = os.path.join(output_dir, 'src.pkl')\n",
    "with open(src_file, 'wb') as f:\n",
    "    pickle.dump(src, f)\n",
    "\n",
    "# Optionally, save the settings for the plot (e.g., view parameters)\n",
    "alignment_settings = {\n",
    "    'azimuth': 180,\n",
    "    'elevation': 90,\n",
    "    'distance': 0.30,\n",
    "    'focalpoint': (-0.03, -0.01, 0.03)\n",
    "}\n",
    "\n",
    "# Save the alignment settings as a pickle file\n",
    "settings_file = os.path.join(output_dir, 'alignment_settings.pkl')\n",
    "with open(settings_file, 'wb') as f:\n",
    "    pickle.dump(alignment_settings, f)\n",
    "\n",
    "print(f\"Data saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.datasets import fetch_fsaverage\n",
    "fetch_fsaverage(verbose=True)\n",
    "\n",
    "fiducials = 'estimated'\n",
    "subject = 'fsaverage'\n",
    "coreg = Coregistration(info, subject,subjects_dir=subject_dir,fiducials=fiducials)\n",
    "coreg.fit_fiducials(verbose=True)\n",
    "coreg.fit_icp(n_iterations=6, nasion_weight=2.0, verbose=True)\n",
    "coreg.omit_head_shape_points(distance=5.0 / 1000)  # distance is in meters\n",
    "coreg.fit_icp(n_iterations=20, nasion_weight=10.0, verbose=True)\n",
    "dists = coreg.compute_dig_mri_distances() * 1e3  # in mm\n",
    "print(\n",
    "    f\"Distance between HSP and MRI (mean/min/max):\\n{np.mean(dists):.2f} mm \"\n",
    "    f\"/ {np.min(dists):.2f} mm / {np.max(dists):.2f} mm\"\n",
    ")\n",
    "trans = coreg.trans\n",
    "trans_fname = os.path.join(output_dir, 'trans.fif')\n",
    "mne.write_trans(trans_fname, coreg.trans,overwrite=True)\n",
    "print(f\"Transformation matrix saved to {trans_fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd = mne.make_forward_solution(\n",
    "info = info,\n",
    "trans = trans,\n",
    "src = src,\n",
    "bem = bem,\n",
    "meg = False,\n",
    "eeg=True,\n",
    "mindist=0.0,\n",
    "n_jobs=8,\n",
    "verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadfield = fwd[\"sol\"][\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_cov = mne.compute_covariance(epochs, tmin=start, tmax=end, method=[\"shrunk\", \"empirical\"], rank=None, verbose=True, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.minimum_norm import read_inverse_operator, apply_inverse_raw, apply_inverse\n",
    "inv_method = \"eLORETA\"  # sLORETA, MNE, dSPM\n",
    "\n",
    "lambda2 = 1 / 6\n",
    "\n",
    "inverse_operator = make_inverse_operator(\n",
    "    info, fwd, noise_cov, depth=0.8,\n",
    ")\n",
    "inverse_operator_fname = os.path.join(output_dir, 'inverse_operator')\n",
    "mne.minimum_norm.write_inverse_operator(inverse_operator_fname, inverse_operator,overwrite=True)\n",
    "print(f\"Inverse operator saved to {inverse_operator_fname}-inv.fif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc = apply_inverse(evoked, inverse_operator, lambda2, method=inv_method, pick_ori=None)\n",
    "# stc = stc.copy().align_src(src)\n",
    "# Save the source estimate (stc)\n",
    "stc_fname = os.path.join(output_dir, 'source_estimate')\n",
    "stc.save(stc_fname,overwrite=True)\n",
    "print(f\"Source estimate saved to {stc_fname}-stc.fif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcs[0].plot(subjects_dir = subject_dir,subject = subject,surface = 'white',hemi = 'both', time_unit='s',time_viewer=True,src = src)\n",
    "\n",
    "stc.plot(subjects_dir = subject_dir,subject = subject,surface = 'white',hemi = 'both', time_unit='s',time_viewer=True,src = src)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogtasks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
